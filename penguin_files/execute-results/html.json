{
  "hash": "17e9fff49c484dcf68896796cd7dd2cc",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Mini Project 2\"\n---\n\n\n## Penguin Random House Web Scraping\n\nOur data comes from the events page in Penguin Random House. You can find the events page using *\\[the Penguin Random House events page\\]*: (<https://www.penguinrandomhouse.com/authors/events/).>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(rvest)\nlibrary(polite)\nlibrary(sf)\nlibrary(maps)\nlibrary(viridis)\nlibrary(leaflet) \nlibrary(htmltools)\nlibrary(httr) \nlibrary(httr2) \nlibrary(janitor)\n```\n:::\n\n\n## Ethical Considerations\n\nWe opted to use the robot.txt paths to determine if data from Penguin's book events was permitted for web scraping. The site’s robots.txt file allowed our bots to access and scrape the data. While we considered implementing a polite function to ensure a respectful approach to data retrieval, this step appeared unnecessary given that the data is public and intended for widespread use.\n\n## Novel Insights Potential and Justification\n\nOur final tibble will hold important information for booksellers, authors, agents, and students to utilize in regards to books/authors from Penguin Random House. We were initially motivated to explore book events from Penguin Random House to inform student decisions to network with agents and authors at various events.\n\nStudents can use our data to answer questions such as:\n\n-   \"Where are events most commonly held?\"\n\n-   \"Which season has the most book events?\"\n\n-   \"What are the best events to attend to network with the right authors and book genres?\"\n\nUpon further reflection, we discovered that our data could also be used by booksellers, book agents, and authors. Booksellers and authors may find our data useful because they can analyze current trends with where authors are going (chain or independent bookstore) and what authors are successful in book events (if we assume multiple book events equals a marketable author).Book agents within Penguin Random House or outside of it (smaller boutique literary agencies or other Big Five publishers) can use our data to answer questions on which authors are holding events, when a certain book is no longer welcomed in event spaces, and perhaps even publicity tactics. This data has relevant applications for different data needs within the publishing industry and for creating engaging data visualizations (including static or leaflet maps).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Step 0: Check if the website allows scraping \nrobotstxt::paths_allowed(\"https://www.penguinrandomhouse.com/authors/events/\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\n#Extract individual information from the events page \ninfo_from_page <- function(event, css_selector) {\n  read_html(event) |> \n#Extracting nodes from the XML by using the CSS path from selector\n  html_nodes(css_selector) |> \n#Extracting text\n  html_text()\n}\n\n#Test, the function works\ninfo_from_page(\"https://www.penguinrandomhouse.com/authors/events/\", \".date-display\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"November 2024\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Scrape info using the CSS path and compile it into a tibble \nscrape_events <- function(url){\n  \n  date <- info_from_page(url, \".start\")\n  book <- info_from_page(url, \".author-of a\")\n  author <- info_from_page(url, \".author-name:nth-child(1)\")\n  host <- info_from_page(url, \".event-location .hdr\")\n  state <- info_from_page(url, \"span:nth-child(4)\")\n  zip_code <- info_from_page(url, \"span:nth-child(5)\")\n  \n  tibble(date = date, \n           book = book, \n           author = author,\n           host = host,\n           state = state)\n  \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Test to see that our tibble looks appropriate\nscrape_events(\"https://www.penguinrandomhouse.com/authors/events/?page=2\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 5\n   date                 book                                  author host  state\n   <chr>                <chr>                                 <chr>  <chr> <chr>\n 1 11/4/2024 at 10:45am All the Colors of the Dark: A Read w… Chris… Litc… SC   \n 2 11/4/2024 at 6:00 PM The Swifts: A Gallery of Rogues       Beth … QUAI… NC   \n 3 11/4/2024 at 7pm     Every Valley                          Charl… Poli… DC   \n 4 11/4/2024 at 6:00    Blackness Is a Gift I Can Give Her    R. Re… ANOT… ON   \n 5 11/4/2024            Classic German Cooking                Luisa… Vass… NY   \n 6 11/5/2024            What She Said                         Eliza… Arts… ON –…\n 7 11/5/2024 at 11AM    The Gulf                              Adam … TINL… ON   \n 8 11/5/2024 at 7pm     Laugh More                            Debbi… Cent… AB   \n 9 11/6/2024 at 12:00pm This Fierce People                    Alan … Geor… VA   \n10 11/6/2024            Fragments of a Paradise               Paul … TYPE… ON   \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#This for loop runs all of the months and all of the days\n#   in one chunk but it is not the most efficient \n\n#If someone is interested in keeping this method in one chunk\n#   they can use this code for the nested for loop.\n\n#Nested for loop with i for months and j for days. \nfor(i in c(10, 11, 12, 1, 2, 3, 4)){\n#Runs to find data for all of the dates in these months\n#   we can compile all of the data together \n  for(j in 1:31){\n#Combining i and j for the dates to keep track of event dates\n    date = str_c(i, \"/\", j, \"/\", \"2024\")\n    url = str_c(\n      \"https://www.penguinrandomhouse.com/authors/events/?datefrom=\",\n      date, \n      \"&dateto=\", \n      date)\n    scrape_events(url)\n  }\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Test chunk to see if our previous code worked with a smaller set of data\n\n#If you wanted to run the previous code chunk, this test \n#   proves that it will give you a larger version\n\ni=11\nj=1\ndate = str_c(i, \"/\", j, \"/\", \"2024\")\nurl = str_c(\n      \"https://www.penguinrandomhouse.com/authors/events/?datefrom=\",\n      date, \n      \"&dateto=\", \n      date)\nscrape_events(url)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 0 × 5\n# ℹ 5 variables: date <chr>, book <chr>, author <chr>, host <chr>, state <chr>\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Running each individual month as a separate \n#   for loop to be more efficient\n\n#Create a list to store your scraped data\noctober <- list()\n  i=10\nfor(j in 1:31){\n    date = str_c(i, \"/\", j, \"/\", \"2024\")\n    url = str_c(\n      \"https://www.penguinrandomhouse.com/authors/events/?datefrom=\",\n      date, \n      \"&dateto=\", \n      date)\n    october[[j]] <- scrape_events(url)\n}\n\n#Create a tibble from the list \noctober_tibble <- bind_rows(october) |> \n  as_tibble()\n  \nnovember <- list()\n  i=11\nfor(j in 1:30){\n    date = str_c(i, \"/\", j, \"/\", \"2024\")\n    url = str_c(\n      \"https://www.penguinrandomhouse.com/authors/events/?datefrom=\",\n      date, \n      \"&dateto=\", \n      date)\n    november[[j]] <- scrape_events(url)\n}\n  \n  november_tibble <- bind_rows(november) |> \n    as_tibble() \n  \ndecember <- list()\n  i=12\nfor(j in 1:31){\n    date = str_c(i, \"/\", j, \"/\", \"2024\")\n    url = str_c(\n      \"https://www.penguinrandomhouse.com/authors/events/?datefrom=\",\n      date, \n      \"&dateto=\", \n      date)\n    december[[j]] <- scrape_events(url)\n}\n  \n  december_tibble <- bind_rows(december) |> \n    as_tibble()\n  \njanuary <- list()\n  i=1\nfor(j in 1:31){\n    date = str_c(i, \"/\", j, \"/\", \"2025\")\n    url = str_c(\n      \"https://www.penguinrandomhouse.com/authors/events/?datefrom=\",\n      date, \n      \"&dateto=\", \n      date)\n    january[[j]] <- scrape_events(url)\n}\n  \njanuary_tibble <- bind_rows(january) |> \n  as_tibble()\n\nfebruary <- list()\n  i=2\nfor(j in 1:28){\n    date = str_c(i, \"/\", j, \"/\", \"2025\")\n    url = str_c(\n      \"https://www.penguinrandomhouse.com/authors/events/?datefrom=\",\n      date, \n      \"&dateto=\", \n      date)\n    february[[j]] <- scrape_events(url)\n}\n  \n  february_tibble <- bind_rows(february) |> \n    as_tibble() \n  \nmarch <- list()\n  i=3\nfor(j in 1:31){\n    date = str_c(i, \"/\", j, \"/\", \"2025\")\n    url = str_c(\n      \"https://www.penguinrandomhouse.com/authors/events/?datefrom=\",\n      date, \n      \"&dateto=\", \n      date)\n    march[[j]] <- scrape_events(url)\n}\n  \n  march_tibble <- bind_rows(march) |> \n    as_tibble() \n  \napril <- list()\n  i=4\nfor(j in 1:30){\n    date = str_c(i, \"/\", j, \"/\", \"2025\")\n    url = str_c(\n      \"https://www.penguinrandomhouse.com/authors/events/?datefrom=\",\n      date, \n      \"&dateto=\", \n      date)\n    april[[j]] <- scrape_events(url)\n}\n  \napril_tibble <- bind_rows(april) |> \n  as_tibble()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Bind all of the tibbles from the previous chunk \n#   together to create one big tibble called events \n\nevents <- rbind(october_tibble,\n                 november_tibble,\n                 december_tibble,\n                 january_tibble,\n                 february_tibble,\n                 march_tibble,\n                 april_tibble)\nevents\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 591 × 5\n   date                 book                                  author host  state\n   <chr>                <chr>                                 <chr>  <chr> <chr>\n 1 11/4/2024 at 10:45am All the Colors of the Dark: A Read w… Chris… Litc… SC   \n 2 11/4/2024 at 6:00 PM The Swifts: A Gallery of Rogues       Beth … QUAI… NC   \n 3 11/4/2024 at 7pm     Every Valley                          Charl… Poli… DC   \n 4 11/4/2024 at 6:00    Blackness Is a Gift I Can Give Her    R. Re… ANOT… ON   \n 5 11/4/2024            Classic German Cooking                Luisa… Vass… NY   \n 6 11/5/2024            What She Said                         Eliza… Arts… ON –…\n 7 11/5/2024 at 11AM    The Gulf                              Adam … TINL… ON   \n 8 11/5/2024 at 7pm     Laugh More                            Debbi… Cent… AB   \n 9 11/6/2024 at 12:00pm This Fierce People                    Alan … Geor… VA   \n10 11/6/2024            Fragments of a Paradise               Jean … TYPE… ON   \n# ℹ 581 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_events <- events |> \n#Separate the time from date to create a separate column\n#   for the time of the events\n  separate(date, into = c(\"date\", \"time\"), sep = \" at \") |> \n#Some of the host names were all caps or had other \n#   abnormalities that we needed to fix\n  mutate(host = str_to_title(host),\n#Some observations had strange patterns in the text (r/n) \n#   that distracted from the host's name \n         host = str_replace_all(host, \"[\\r\\n]\", \" \"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 191 rows [5, 6, 10, 14,\n15, 17, 21, 23, 24, 31, 35, 40, 48, 49, 51, 56, 67, 68, 74, 79, ...].\n```\n\n\n:::\n\n```{.r .cell-code}\npenguin_events\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 591 × 6\n   date      time    book                                     author host  state\n   <chr>     <chr>   <chr>                                    <chr>  <chr> <chr>\n 1 11/4/2024 10:45am All the Colors of the Dark: A Read with… Chris… Litc… SC   \n 2 11/4/2024 6:00 PM The Swifts: A Gallery of Rogues          Beth … Quai… NC   \n 3 11/4/2024 7pm     Every Valley                             Charl… Poli… DC   \n 4 11/4/2024 6:00    Blackness Is a Gift I Can Give Her       R. Re… Anot… ON   \n 5 11/4/2024 <NA>    Classic German Cooking                   Luisa… Vass… NY   \n 6 11/5/2024 <NA>    What She Said                            Eliza… Arts… ON –…\n 7 11/5/2024 11AM    The Gulf                                 Adam … Tinl… ON   \n 8 11/5/2024 7pm     Laugh More                               Debbi… Cent… AB   \n 9 11/6/2024 12:00pm This Fierce People                       Alan … Geor… VA   \n10 11/6/2024 <NA>    Fragments of a Paradise                  Jean … Type… ON   \n# ℹ 581 more rows\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}